<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>anon.evaluate_experiment_results API documentation</title>
<meta name="description" content="Main application to evaluate and plot experiment results" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>anon.evaluate_experiment_results</code></h1>
</header>
<section id="section-intro">
<p>Main application to evaluate and plot experiment results</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Main application to evaluate and plot experiment results&#34;&#34;&#34;
import json
import os
import statistics

import pandas as pd
import seaborn as sns

import matplotlib.pyplot as plt

from pathlib import Path

plt.rcParams.update({
    &#34;pgf.texsystem&#34;: &#34;pdflatex&#34;,
    &#39;font.family&#39;: &#39;serif&#39;,
    &#39;text.usetex&#39;: True,
    &#39;pgf.rcfonts&#39;: False,
    &#39;font.size&#39;: 16
})


y_min = -0.05
y_max = 1.05
y_ticks = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
fig_width = 8
fig_height = 8
colors = [&#39;#1F77B4&#39;, &#39;#FF7F0E&#39;, &#39;#2CA02C&#39;, &#39;#D62728&#39;, &#39;#9467BD&#39;, &#39;#8C564B&#39;, &#39;#E377C2&#39;, &#39;#7F7F7F&#39;, &#39;#BCBD22&#39;, &#39;#17BECF&#39;, &#39;lime&#39;, &#39;darkblue&#39;, &#39;magenta&#39;]

information_loss_filter = [&#34;0_0.&#34;, &#34;0_1.&#34;, &#34;0_2.&#34;, &#34;0_3.&#34;, &#34;0_4.&#34;, &#34;0_5.&#34;, &#34;1_0.&#34;, &#34;gdf&#34;]


def merge_information_loss_results(path, information_loss_files, destination):
    &#34;&#34;&#34;Merges partial information loss files to a single file&#34;&#34;&#34;
    data_frames = []
    if len(information_loss_files) &gt; 0:
        for information_loss_file in information_loss_files:
            data_frames.append(pd.read_csv(path / information_loss_file, index_col=&#34;k&#34;))
        df_il = pd.concat(data_frames, axis=1)
        df_il = df_il.reindex(sorted(df_il.columns), axis=1)
        df_il.to_csv(path / destination)


def merge_partition_json(path, partition_size_files, destination):
    &#34;&#34;&#34;Merges partial partition size files to a single file&#34;&#34;&#34;
    merged_partition_sizes = {}
    if len(partition_size_files) &gt; 0:
        for partition_size_file in partition_size_files:
            with open(path / partition_size_file) as partition_size_json:
                loaded_partition_sizes = json.load(partition_size_json)
                for partitioning_strategy in loaded_partition_sizes:
                    merged_partition_sizes[partitioning_strategy] = loaded_partition_sizes[partitioning_strategy]
    merged_partition_sizes = {k: v for k, v in sorted(merged_partition_sizes.items())}

    with open(path / destination, &#39;w&#39;) as partition_size_file:
        json.dump(merged_partition_sizes, partition_size_file, ensure_ascii=False)


def merge_experiment_results(path):
    raw_files = [os.path.basename(child) for child in path.iterdir()]

    relational_information_loss_files = [child for child in raw_files if child.startswith(&#34;relational_information_loss_&#34;) and any(f in child for f in information_loss_filter)]
    textual_information_loss_files = [child for child in raw_files if child.startswith(&#34;textual_information_loss_&#34;) and any(f in child for f in information_loss_filter)]
    total_information_loss_files = [child for child in raw_files if child.startswith(&#34;total_information_loss_&#34;) and any(f in child for f in information_loss_filter)]
    partition_sizes_files = [child for child in raw_files if child.startswith(&#34;partition_distribution_&#34;)]
    partition_split_files = [child for child in raw_files if child.startswith(&#34;partition_splits_&#34;)]

    merge_information_loss_results(path, relational_information_loss_files, &#34;relational_information_loss.csv&#34;)
    merge_information_loss_results(path, textual_information_loss_files, &#34;textual_information_loss.csv&#34;)
    merge_information_loss_results(path, total_information_loss_files, &#34;total_information_loss.csv&#34;)
    merge_partition_json(path, partition_sizes_files, &#34;partition_distribution.json&#34;)
    merge_partition_json(path, partition_split_files, &#34;partition_splits.json&#34;)


# Taken from https://stackoverflow.com/questions/16592222/matplotlib-group-boxplots
def set_box_color(bp, color):
    plt.setp(bp[&#39;boxes&#39;], color=color)
    plt.setp(bp[&#39;whiskers&#39;], color=color)
    plt.setp(bp[&#39;caps&#39;], color=color)
    plt.setp(bp[&#39;medians&#39;], color=&#39;#000000&#39;)


def main():
    raw_path = Path(&#34;experiment_results/raw&#34;)
    raw_directories = [child for child in raw_path.iterdir() if child.is_dir()]

    ps_c_blogs_fig, ps_c_blogs_axes = plt.subplots(nrows=7, ncols=2, sharex=&#39;col&#39;, sharey=&#39;row&#39;)
    ps_c_hotels_fig, ps_c_hotels_axes = plt.subplots(nrows=7, ncols=2, sharex=&#39;col&#39;, sharey=&#39;row&#39;)

    for exp_run, raw_directory in enumerate(raw_directories):

        print(&#34;Creating plots for {}&#34;.format(raw_directory))

        detailed_il_files = [child for child in raw_directory.iterdir() if os.path.basename(child).startswith(&#34;detailed_textual_information_loss&#34;)]

        # Merge results to single files per run
        merge_experiment_results(raw_directory)

        # Load result files
        with open(raw_directory / &#39;partition_distribution.json&#39;) as json_file:
            partition_sizes = json.load(json_file)

        with open(raw_directory / &#39;partition_splits.json&#39;) as json_file:
            partition_splits = json.load(json_file)

        total_information_loss = pd.read_csv(raw_directory / &#34;total_information_loss.csv&#34;, index_col=&#34;k&#34;)
        relational_information_loss = pd.read_csv(raw_directory / &#34;relational_information_loss.csv&#34;, index_col=&#34;k&#34;)
        textual_information_loss = pd.read_csv(raw_directory / &#34;textual_information_loss.csv&#34;, index_col=&#34;k&#34;)

        # Read all available strategies from partition sizes
        il_strategies = total_information_loss.columns
        partionioning_strategies = [x for x in list(partition_sizes.keys())]

        # Define legend names
        il_legend_names = [x.replace(&#34;mondrian&#34;, &#34;mon&#34;).replace(&#34;-&#34;, r&#34;, $\lambda=&#34;) for x in il_strategies]
        il_legend_names = [x + &#34;$&#34; if &#34;mon&#34; in x else x for x in il_legend_names]
        part_legend_names = [x.replace(&#34;mondrian&#34;, &#34;mon&#34;).replace(&#34;-&#34;, r&#34;, $\lambda=&#34;) for x in partionioning_strategies]
        part_legend_names = [x + &#34;$&#34; if &#34;mon&#34; in x else x for x in part_legend_names]

        # Read values for k
        k_values = [int(k) for k in partition_sizes[partionioning_strategies[0]].keys()]

        result_directory = Path(&#34;experiment_results/results&#34;) / os.path.basename(raw_directory)
        result_directory.mkdir(parents=True, exist_ok=True)

        # Transform information loss straight to latex tables
        total_information_loss.to_latex(buf=result_directory / &#34;total_information_loss.tex&#34;)
        relational_information_loss.to_latex(buf=result_directory / &#34;relational_information_loss.tex&#34;)
        textual_information_loss.to_latex(buf=result_directory / &#34;textual_information_loss.tex&#34;)

        # Calculate mean and std for partition sizes
        partioning_distribution_table = pd.DataFrame(columns=pd.MultiIndex.from_product([part_legend_names, [&#34;count&#34;, &#34;mean&#34;, &#34;std&#34;]]), index=k_values)

        for ii, strategy in enumerate(partition_sizes):
            values = partition_sizes[strategy]
            for k in values:
                partition_results = values[k]
                partioning_distribution_table.loc[int(k), (part_legend_names[ii], &#34;count&#34;)] = len(partition_results)
                partioning_distribution_table.loc[int(k), (part_legend_names[ii], &#34;mean&#34;)] = statistics.mean(partition_results)
                if len(partition_results) &gt; 1:
                    partioning_distribution_table.loc[int(k), (part_legend_names[ii], &#34;std&#34;)] = statistics.stdev(partition_results)
                else:
                    partioning_distribution_table.loc[int(k), (part_legend_names[ii], &#34;std&#34;)] = 0

        partioning_distribution_table.to_csv(result_directory / &#39;partition_distribution.csv&#39;)
        partioning_distribution_table.transpose().to_latex(buf=result_directory / &#34;partition_distribution.tex&#34;, float_format=&#34;{:0.2f}&#34;.format)

        # Calculate number of relational and textual splits
        splits_legend_names = [name for name in part_legend_names if &#34;mon&#34; in name]
        partition_splits_table = pd.DataFrame(columns=pd.MultiIndex.from_product([k_values, splits_legend_names]), index=[&#34;relational&#34;, &#34;textual&#34;])

        for ii, strategy in enumerate(partition_splits):
            values = partition_splits[strategy]
            for k in values:
                relational_splits = values[k][&#34;relational&#34;]
                textual_splits = values[k][&#34;textual&#34;]
                partition_splits_table.loc[&#34;relational&#34;, (int(k), splits_legend_names[ii])] = relational_splits
                partition_splits_table.loc[&#34;textual&#34;, (int(k), splits_legend_names[ii])] = textual_splits

        partition_splits_table.to_csv(result_directory / &#39;partition_splits.csv&#39;)

        # Plot partition distributions
        inverted_partitions = {}
        for strategy in partition_sizes:
            values = partition_sizes[strategy]
            for k in values:
                inverted_partitions.setdefault(k, {})[strategy] = values[k]

        for k in inverted_partitions:
            fig = plt.figure()
            fig.set_figheight(fig_height)
            fig.set_figwidth(fig_width)

            plt.boxplot([arr for arr in inverted_partitions[k].values()], positions=list(range(1, len(part_legend_names) + 1)), labels=part_legend_names, sym=&#39;&#39;, widths=0.6)

            plt.xlabel(&#39;partitioning strategy&#39;)
            plt.ylabel(&#39;partition size&#39;, rotation=90)
            fig.autofmt_xdate()
            fig.tight_layout()
            fig.savefig(result_directory / &#39;partition_distribution-k_{}.pgf&#39;.format(k))
            fig.savefig(result_directory / &#39;partition_distribution-k_{}.pdf&#39;.format(k), bbox_inches=&#39;tight&#39;)

        # Plots for number of splits per strategy for each value of k
        for jj, k in enumerate(k_values):
            ps_plot = partition_splits_table[k].transpose().plot(kind=&#39;bar&#39;, stacked=True)
            ps_plot.set_xlabel(r&#34;$\lambda$&#34;)
            ps_plot.set_xticklabels([s.replace(&#39;mon, $\\lambda=&#39;, &#39;&#39;)[:-1] for s in splits_legend_names], rotation=0)
            ps_plot.set_ylabel(&#39;number of splits&#39;)
            ps_plot.legend([&#34;relational attribute&#34;, &#34;textual attribute&#34;], loc=&#39;lower center&#39;, ncol=2, fancybox=True, bbox_to_anchor=(0.5, -0.2))
            ps_fig = ps_plot.get_figure()
            ps_fig.set_figheight(fig_height)
            ps_fig.set_figwidth(fig_width)
            ps_fig.tight_layout()
            ps_fig.savefig(result_directory / &#39;partition_splits-k_{}.pgf&#39;.format(k))
            ps_fig.savefig(result_directory / &#39;partition_splits-k_{}.pdf&#39;.format(k), bbox_inches=&#39;tight&#39;)

            str_result_dir = str(result_directory)
            if &#34;blog_authorship_corpus&#34; in str_result_dir:
                if &#34;all_entities&#34; in str_result_dir:
                    ps_combined_plot = partition_splits_table[k].transpose().plot(ax=ps_c_blogs_axes[jj, 0], kind=&#39;bar&#39;, stacked=True, legend=False)
                else:
                    ps_combined_plot = partition_splits_table[k].transpose().plot(ax=ps_c_blogs_axes[jj, 1], kind=&#39;bar&#39;, stacked=True, legend=False)
            else:
                if &#34;all_entities&#34; in str_result_dir:
                    ps_combined_plot = partition_splits_table[k].transpose().plot(ax=ps_c_hotels_axes[jj, 0], kind=&#39;bar&#39;, stacked=True, legend=False)
                else:
                    ps_combined_plot = partition_splits_table[k].transpose().plot(ax=ps_c_hotels_axes[jj, 1], kind=&#39;bar&#39;, stacked=True, legend=False)

            ps_combined_plot.set_xlabel(r&#34;$\lambda$&#34;)
            ps_combined_plot.set_xticklabels([s.replace(&#39;mon, $\\lambda=&#39;, &#39;&#39;)[:-1] for s in splits_legend_names], rotation=0)

        # Plot detailed textual information loss
        attribute_details = {}
        for f in detailed_il_files:
            strategy = f.name.split(&#34;loss_&#34;)[1].split(&#34;.&#34;)[0].replace(&#34;_&#34;, &#34;.&#34;)
            if &#39;gdf&#39; not in strategy:
                strategy = r&#34;mon, $\lambda={}$&#34;.format(strategy)
            detailed_xil = pd.read_csv(f, header=[0, 1], index_col=[0])
            for lvl in [0, 1]:
                detailed_xil.columns.set_levels(detailed_xil.columns.levels[lvl].str.replace(&#34;_&#34;, &#34;\\_&#34;), level=lvl, inplace=True)
            detailed_xil.sort_index(axis=1, inplace=True)

            for attr in detailed_xil.columns.get_level_values(0):
                attr_xil = detailed_xil[attr]
                attribute_details.setdefault(attr, {})[strategy] = attr_xil

        for attr in attribute_details:
            # Single heatmap plots
            for ii, key in enumerate(sorted(attribute_details[attr])):
                heatmap_fig = plt.figure()
                df = attribute_details[attr][key].drop(&#34;total&#34;, axis=1).dropna(axis=1)
                sns_plot = sns.heatmap(df, xticklabels=True, yticklabels=True, cbar=True, vmin=0.2, vmax=1)
                sns_plot.tick_params(left=False, labelbottom=False, bottom=False, top=False, labeltop=True)
                sns_plot.set_xticklabels(sns_plot.get_xticklabels(), va=&#34;bottom&#34;, rotation=90)
                heatmap_fig.set_figheight(0.75 * fig_height)
                heatmap_fig.set_figwidth(fig_width)
                heatmap_fig.tight_layout()
                if &#34;mon&#34; in key:
                    file_ext = key.replace(&#39;mon, $\\lambda=&#39;, &#39;&#39;)[:-1].replace(&#39;.&#39;, &#34;_&#34;)
                else:
                    file_ext = key
                heatmap_fig.savefig(result_directory / &#34;heatmap_{}_{}.pdf&#34;.format(attr.replace(&#34;\\&#34;, &#34;&#34;), file_ext), bbox_inches=&#39;tight&#39;)
                heatmap_fig.savefig(result_directory / &#34;heatmap_{}_{}.pgf&#34;.format(attr.replace(&#34;\\&#34;, &#34;&#34;), file_ext), bbox_inches=&#39;tight&#39;)

            # Combined heatmap plots
            combined_heatmap, ax = plt.subplots(ncols=3, nrows=4, sharey=True, sharex=True)
            cbar_ax = combined_heatmap.add_axes([.91, .25, .03, .4])
            for ii, key in enumerate(sorted(attribute_details[attr])):
                df = attribute_details[attr][key].drop(&#34;total&#34;, axis=1).dropna(axis=1)
                sub_ax = ax[ii // 3, ii % 3]
                sns_plot = sns.heatmap(df, xticklabels=True, yticklabels=True, ax=sub_ax, cbar=ii == 0, vmin=0.2, vmax=1, cbar_ax=None if ii else cbar_ax)
                sub_ax.set_title(key, y=-0.1)
                ltop = True if ii &lt; 3 else False
                sub_ax.tick_params(left=False, labelbottom=False, bottom=False, top=False, labeltop=ltop)
                if ltop:
                    sub_ax.set_xticklabels(sns_plot.get_xticklabels(), va=&#34;bottom&#34;, rotation=90)
                if ii % 3 != 0:
                    sub_ax.set_ylabel(&#39;&#39;)
            combined_heatmap.set_figheight(2 * fig_height)
            combined_heatmap.set_figwidth(2 * fig_width)
            combined_heatmap.tight_layout(rect=[0, 0, .9, 1])
            combined_heatmap.savefig(result_directory / &#34;heatmap_{}.pdf&#34;.format(attr.replace(&#34;\\&#34;, &#34;&#34;)), bbox_inches=&#39;tight&#39;)
            combined_heatmap.savefig(result_directory / &#34;heatmap_{}.pgf&#34;.format(attr.replace(&#34;\\&#34;, &#34;&#34;)), bbox_inches=&#39;tight&#39;)

        # Plot for total information loss
        til_plot = total_information_loss.plot(xticks=k_values, marker=&#39;o&#39;, color=colors)
        til_plot.legend(il_legend_names, loc=&#39;lower center&#39;, ncol=3, fancybox=True, bbox_to_anchor=(0.5, -0.3))
        til_fig = til_plot.get_figure()
        til_fig.set_figheight(fig_height)
        til_fig.set_figwidth(fig_width)
        til_plot.set_xlabel(&#39;k&#39;)
        til_plot.set_ylabel(&#39;NCP&#39;, rotation=90)
        til_plot.set_ylim([y_min, y_max])
        til_plot.set_yticks(y_ticks)
        til_fig.tight_layout()
        til_fig.savefig(result_directory / &#39;total_information_loss.pgf&#39;)
        til_fig.savefig(result_directory / &#39;total_information_loss.pdf&#39;, bbox_inches=&#39;tight&#39;)

        # Plot for relational information loss
        ril_plot = relational_information_loss.plot(xticks=k_values, marker=&#39;o&#39;, color=colors)
        ril_plot.legend(il_legend_names, loc=&#39;lower center&#39;, ncol=3, fancybox=True, bbox_to_anchor=(0.5, -0.3))
        ril_fig = ril_plot.get_figure()
        ril_fig.set_figheight(fig_height)
        ril_fig.set_figwidth(fig_width)
        ril_plot.set_xlabel(&#39;k&#39;)
        ril_plot.set_ylabel(&#39;$NCP_A$&#39;, rotation=90)
        ril_plot.set_ylim([y_min, y_max])
        ril_plot.set_yticks(y_ticks)
        ril_fig.tight_layout()
        ril_fig.savefig(result_directory / &#39;relational_information_loss.pgf&#39;)
        ril_fig.savefig(result_directory / &#39;relational_information_loss.pdf&#39;, bbox_inches=&#39;tight&#39;)

        # Plot for textual information loss
        xil_plot = textual_information_loss.plot(xticks=k_values, marker=&#39;o&#39;, color=colors)
        xil_plot.legend(il_legend_names, loc=&#39;lower center&#39;, ncol=3, fancybox=True, bbox_to_anchor=(0.5, -0.3))
        xil_fig = xil_plot.get_figure()
        xil_fig.set_figheight(fig_height)
        xil_fig.set_figwidth(fig_width)
        xil_plot.set_xlabel(&#39;k&#39;)
        xil_plot.set_ylabel(&#39;$NCP_X$&#39;, rotation=90)
        xil_plot.set_ylim([y_min, y_max])
        xil_plot.set_yticks(y_ticks)
        xil_fig.tight_layout()
        xil_fig.savefig(result_directory / &#39;textual_information_loss.pgf&#39;)
        xil_fig.savefig(result_directory / &#39;textual_information_loss.pdf&#39;, bbox_inches=&#39;tight&#39;)

        xil_zoomed = textual_information_loss.plot(xticks=k_values, marker=&#39;o&#39;, color=colors)
        xil_zoomed.legend(il_legend_names, loc=&#39;lower center&#39;, ncol=3, fancybox=True, bbox_to_anchor=(0.5, -0.3))
        xil_zoomed_fig = xil_zoomed.get_figure()
        xil_zoomed_fig.set_figheight(fig_height)
        xil_zoomed_fig.set_figwidth(fig_width)
        xil_zoomed.set_xlabel(&#39;k&#39;)
        xil_zoomed.set_ylabel(&#39;$NCP_X$&#39;, rotation=90)
        xil_zoomed_fig.tight_layout()
        xil_zoomed_fig.savefig(result_directory / &#39;textual_information_loss_zoomed.pgf&#39;)
        xil_zoomed_fig.savefig(result_directory / &#39;textual_information_loss_zoomed.pdf&#39;, bbox_inches=&#39;tight&#39;)

    # Combined plot
    combined_results = [&#34;blogs&#34;, &#34;hotels&#34;]
    pad = 5  # in points
    for ii, (ps_c_fig, ps_c_axes) in enumerate([(ps_c_blogs_fig, ps_c_blogs_axes), (ps_c_hotels_fig, ps_c_hotels_axes)]):
        handles_labels = [ax.get_legend_handles_labels() for ax in ps_c_fig.axes]
        handles, labels = [sum(lol, []) for lol in zip(*handles_labels)]
        ps_c_fig.legend(handles, [&#34;relational attribute&#34;, &#34;textual attribute&#34;], loc=&#39;lower center&#39;, ncol=2, fancybox=True, bbox_to_anchor=(0.53, -0.03))
        ps_c_fig.set_figheight(2 * fig_height)
        ps_c_fig.set_figwidth(2 * fig_width)

        cols = [&#34;all entities&#34;, &#34;only GPE&#34;]
        rows = [&#34;$k={}$&#34;.format(k) for k in k_values]

        for ax, col in zip(ps_c_axes[0], cols):
            ax.set_title(col)

        for ax, row in zip(ps_c_axes[:, 0], rows):
            ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),
                        xycoords=ax.yaxis.label, textcoords=&#39;offset points&#39;,
                        size=&#39;large&#39;, ha=&#39;right&#39;, va=&#39;center&#39;, rotation=90)

        for ax, row in zip(ps_c_axes[:, 0], rows):
            ax.set_ylabel(&#34;number of splits&#34;, rotation=90)

        ps_c_fig.subplots_adjust(left=0.15, top=0.95)
        ps_c_fig.tight_layout()
        results_path = Path(&#34;experiment_results/results&#34;)
        ps_c_fig.savefig(results_path / &#39;partition_splits_combined_{}.pgf&#39;.format(combined_results[ii]), bbox_inches=&#39;tight&#39;)
        ps_c_fig.savefig(results_path / &#39;partition_splits_combined_{}.pdf&#39;.format(combined_results[ii]), bbox_inches=&#39;tight&#39;)


if __name__ == &#34;__main__&#34;:
    main()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="anon.evaluate_experiment_results.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main():
    raw_path = Path(&#34;experiment_results/raw&#34;)
    raw_directories = [child for child in raw_path.iterdir() if child.is_dir()]

    ps_c_blogs_fig, ps_c_blogs_axes = plt.subplots(nrows=7, ncols=2, sharex=&#39;col&#39;, sharey=&#39;row&#39;)
    ps_c_hotels_fig, ps_c_hotels_axes = plt.subplots(nrows=7, ncols=2, sharex=&#39;col&#39;, sharey=&#39;row&#39;)

    for exp_run, raw_directory in enumerate(raw_directories):

        print(&#34;Creating plots for {}&#34;.format(raw_directory))

        detailed_il_files = [child for child in raw_directory.iterdir() if os.path.basename(child).startswith(&#34;detailed_textual_information_loss&#34;)]

        # Merge results to single files per run
        merge_experiment_results(raw_directory)

        # Load result files
        with open(raw_directory / &#39;partition_distribution.json&#39;) as json_file:
            partition_sizes = json.load(json_file)

        with open(raw_directory / &#39;partition_splits.json&#39;) as json_file:
            partition_splits = json.load(json_file)

        total_information_loss = pd.read_csv(raw_directory / &#34;total_information_loss.csv&#34;, index_col=&#34;k&#34;)
        relational_information_loss = pd.read_csv(raw_directory / &#34;relational_information_loss.csv&#34;, index_col=&#34;k&#34;)
        textual_information_loss = pd.read_csv(raw_directory / &#34;textual_information_loss.csv&#34;, index_col=&#34;k&#34;)

        # Read all available strategies from partition sizes
        il_strategies = total_information_loss.columns
        partionioning_strategies = [x for x in list(partition_sizes.keys())]

        # Define legend names
        il_legend_names = [x.replace(&#34;mondrian&#34;, &#34;mon&#34;).replace(&#34;-&#34;, r&#34;, $\lambda=&#34;) for x in il_strategies]
        il_legend_names = [x + &#34;$&#34; if &#34;mon&#34; in x else x for x in il_legend_names]
        part_legend_names = [x.replace(&#34;mondrian&#34;, &#34;mon&#34;).replace(&#34;-&#34;, r&#34;, $\lambda=&#34;) for x in partionioning_strategies]
        part_legend_names = [x + &#34;$&#34; if &#34;mon&#34; in x else x for x in part_legend_names]

        # Read values for k
        k_values = [int(k) for k in partition_sizes[partionioning_strategies[0]].keys()]

        result_directory = Path(&#34;experiment_results/results&#34;) / os.path.basename(raw_directory)
        result_directory.mkdir(parents=True, exist_ok=True)

        # Transform information loss straight to latex tables
        total_information_loss.to_latex(buf=result_directory / &#34;total_information_loss.tex&#34;)
        relational_information_loss.to_latex(buf=result_directory / &#34;relational_information_loss.tex&#34;)
        textual_information_loss.to_latex(buf=result_directory / &#34;textual_information_loss.tex&#34;)

        # Calculate mean and std for partition sizes
        partioning_distribution_table = pd.DataFrame(columns=pd.MultiIndex.from_product([part_legend_names, [&#34;count&#34;, &#34;mean&#34;, &#34;std&#34;]]), index=k_values)

        for ii, strategy in enumerate(partition_sizes):
            values = partition_sizes[strategy]
            for k in values:
                partition_results = values[k]
                partioning_distribution_table.loc[int(k), (part_legend_names[ii], &#34;count&#34;)] = len(partition_results)
                partioning_distribution_table.loc[int(k), (part_legend_names[ii], &#34;mean&#34;)] = statistics.mean(partition_results)
                if len(partition_results) &gt; 1:
                    partioning_distribution_table.loc[int(k), (part_legend_names[ii], &#34;std&#34;)] = statistics.stdev(partition_results)
                else:
                    partioning_distribution_table.loc[int(k), (part_legend_names[ii], &#34;std&#34;)] = 0

        partioning_distribution_table.to_csv(result_directory / &#39;partition_distribution.csv&#39;)
        partioning_distribution_table.transpose().to_latex(buf=result_directory / &#34;partition_distribution.tex&#34;, float_format=&#34;{:0.2f}&#34;.format)

        # Calculate number of relational and textual splits
        splits_legend_names = [name for name in part_legend_names if &#34;mon&#34; in name]
        partition_splits_table = pd.DataFrame(columns=pd.MultiIndex.from_product([k_values, splits_legend_names]), index=[&#34;relational&#34;, &#34;textual&#34;])

        for ii, strategy in enumerate(partition_splits):
            values = partition_splits[strategy]
            for k in values:
                relational_splits = values[k][&#34;relational&#34;]
                textual_splits = values[k][&#34;textual&#34;]
                partition_splits_table.loc[&#34;relational&#34;, (int(k), splits_legend_names[ii])] = relational_splits
                partition_splits_table.loc[&#34;textual&#34;, (int(k), splits_legend_names[ii])] = textual_splits

        partition_splits_table.to_csv(result_directory / &#39;partition_splits.csv&#39;)

        # Plot partition distributions
        inverted_partitions = {}
        for strategy in partition_sizes:
            values = partition_sizes[strategy]
            for k in values:
                inverted_partitions.setdefault(k, {})[strategy] = values[k]

        for k in inverted_partitions:
            fig = plt.figure()
            fig.set_figheight(fig_height)
            fig.set_figwidth(fig_width)

            plt.boxplot([arr for arr in inverted_partitions[k].values()], positions=list(range(1, len(part_legend_names) + 1)), labels=part_legend_names, sym=&#39;&#39;, widths=0.6)

            plt.xlabel(&#39;partitioning strategy&#39;)
            plt.ylabel(&#39;partition size&#39;, rotation=90)
            fig.autofmt_xdate()
            fig.tight_layout()
            fig.savefig(result_directory / &#39;partition_distribution-k_{}.pgf&#39;.format(k))
            fig.savefig(result_directory / &#39;partition_distribution-k_{}.pdf&#39;.format(k), bbox_inches=&#39;tight&#39;)

        # Plots for number of splits per strategy for each value of k
        for jj, k in enumerate(k_values):
            ps_plot = partition_splits_table[k].transpose().plot(kind=&#39;bar&#39;, stacked=True)
            ps_plot.set_xlabel(r&#34;$\lambda$&#34;)
            ps_plot.set_xticklabels([s.replace(&#39;mon, $\\lambda=&#39;, &#39;&#39;)[:-1] for s in splits_legend_names], rotation=0)
            ps_plot.set_ylabel(&#39;number of splits&#39;)
            ps_plot.legend([&#34;relational attribute&#34;, &#34;textual attribute&#34;], loc=&#39;lower center&#39;, ncol=2, fancybox=True, bbox_to_anchor=(0.5, -0.2))
            ps_fig = ps_plot.get_figure()
            ps_fig.set_figheight(fig_height)
            ps_fig.set_figwidth(fig_width)
            ps_fig.tight_layout()
            ps_fig.savefig(result_directory / &#39;partition_splits-k_{}.pgf&#39;.format(k))
            ps_fig.savefig(result_directory / &#39;partition_splits-k_{}.pdf&#39;.format(k), bbox_inches=&#39;tight&#39;)

            str_result_dir = str(result_directory)
            if &#34;blog_authorship_corpus&#34; in str_result_dir:
                if &#34;all_entities&#34; in str_result_dir:
                    ps_combined_plot = partition_splits_table[k].transpose().plot(ax=ps_c_blogs_axes[jj, 0], kind=&#39;bar&#39;, stacked=True, legend=False)
                else:
                    ps_combined_plot = partition_splits_table[k].transpose().plot(ax=ps_c_blogs_axes[jj, 1], kind=&#39;bar&#39;, stacked=True, legend=False)
            else:
                if &#34;all_entities&#34; in str_result_dir:
                    ps_combined_plot = partition_splits_table[k].transpose().plot(ax=ps_c_hotels_axes[jj, 0], kind=&#39;bar&#39;, stacked=True, legend=False)
                else:
                    ps_combined_plot = partition_splits_table[k].transpose().plot(ax=ps_c_hotels_axes[jj, 1], kind=&#39;bar&#39;, stacked=True, legend=False)

            ps_combined_plot.set_xlabel(r&#34;$\lambda$&#34;)
            ps_combined_plot.set_xticklabels([s.replace(&#39;mon, $\\lambda=&#39;, &#39;&#39;)[:-1] for s in splits_legend_names], rotation=0)

        # Plot detailed textual information loss
        attribute_details = {}
        for f in detailed_il_files:
            strategy = f.name.split(&#34;loss_&#34;)[1].split(&#34;.&#34;)[0].replace(&#34;_&#34;, &#34;.&#34;)
            if &#39;gdf&#39; not in strategy:
                strategy = r&#34;mon, $\lambda={}$&#34;.format(strategy)
            detailed_xil = pd.read_csv(f, header=[0, 1], index_col=[0])
            for lvl in [0, 1]:
                detailed_xil.columns.set_levels(detailed_xil.columns.levels[lvl].str.replace(&#34;_&#34;, &#34;\\_&#34;), level=lvl, inplace=True)
            detailed_xil.sort_index(axis=1, inplace=True)

            for attr in detailed_xil.columns.get_level_values(0):
                attr_xil = detailed_xil[attr]
                attribute_details.setdefault(attr, {})[strategy] = attr_xil

        for attr in attribute_details:
            # Single heatmap plots
            for ii, key in enumerate(sorted(attribute_details[attr])):
                heatmap_fig = plt.figure()
                df = attribute_details[attr][key].drop(&#34;total&#34;, axis=1).dropna(axis=1)
                sns_plot = sns.heatmap(df, xticklabels=True, yticklabels=True, cbar=True, vmin=0.2, vmax=1)
                sns_plot.tick_params(left=False, labelbottom=False, bottom=False, top=False, labeltop=True)
                sns_plot.set_xticklabels(sns_plot.get_xticklabels(), va=&#34;bottom&#34;, rotation=90)
                heatmap_fig.set_figheight(0.75 * fig_height)
                heatmap_fig.set_figwidth(fig_width)
                heatmap_fig.tight_layout()
                if &#34;mon&#34; in key:
                    file_ext = key.replace(&#39;mon, $\\lambda=&#39;, &#39;&#39;)[:-1].replace(&#39;.&#39;, &#34;_&#34;)
                else:
                    file_ext = key
                heatmap_fig.savefig(result_directory / &#34;heatmap_{}_{}.pdf&#34;.format(attr.replace(&#34;\\&#34;, &#34;&#34;), file_ext), bbox_inches=&#39;tight&#39;)
                heatmap_fig.savefig(result_directory / &#34;heatmap_{}_{}.pgf&#34;.format(attr.replace(&#34;\\&#34;, &#34;&#34;), file_ext), bbox_inches=&#39;tight&#39;)

            # Combined heatmap plots
            combined_heatmap, ax = plt.subplots(ncols=3, nrows=4, sharey=True, sharex=True)
            cbar_ax = combined_heatmap.add_axes([.91, .25, .03, .4])
            for ii, key in enumerate(sorted(attribute_details[attr])):
                df = attribute_details[attr][key].drop(&#34;total&#34;, axis=1).dropna(axis=1)
                sub_ax = ax[ii // 3, ii % 3]
                sns_plot = sns.heatmap(df, xticklabels=True, yticklabels=True, ax=sub_ax, cbar=ii == 0, vmin=0.2, vmax=1, cbar_ax=None if ii else cbar_ax)
                sub_ax.set_title(key, y=-0.1)
                ltop = True if ii &lt; 3 else False
                sub_ax.tick_params(left=False, labelbottom=False, bottom=False, top=False, labeltop=ltop)
                if ltop:
                    sub_ax.set_xticklabels(sns_plot.get_xticklabels(), va=&#34;bottom&#34;, rotation=90)
                if ii % 3 != 0:
                    sub_ax.set_ylabel(&#39;&#39;)
            combined_heatmap.set_figheight(2 * fig_height)
            combined_heatmap.set_figwidth(2 * fig_width)
            combined_heatmap.tight_layout(rect=[0, 0, .9, 1])
            combined_heatmap.savefig(result_directory / &#34;heatmap_{}.pdf&#34;.format(attr.replace(&#34;\\&#34;, &#34;&#34;)), bbox_inches=&#39;tight&#39;)
            combined_heatmap.savefig(result_directory / &#34;heatmap_{}.pgf&#34;.format(attr.replace(&#34;\\&#34;, &#34;&#34;)), bbox_inches=&#39;tight&#39;)

        # Plot for total information loss
        til_plot = total_information_loss.plot(xticks=k_values, marker=&#39;o&#39;, color=colors)
        til_plot.legend(il_legend_names, loc=&#39;lower center&#39;, ncol=3, fancybox=True, bbox_to_anchor=(0.5, -0.3))
        til_fig = til_plot.get_figure()
        til_fig.set_figheight(fig_height)
        til_fig.set_figwidth(fig_width)
        til_plot.set_xlabel(&#39;k&#39;)
        til_plot.set_ylabel(&#39;NCP&#39;, rotation=90)
        til_plot.set_ylim([y_min, y_max])
        til_plot.set_yticks(y_ticks)
        til_fig.tight_layout()
        til_fig.savefig(result_directory / &#39;total_information_loss.pgf&#39;)
        til_fig.savefig(result_directory / &#39;total_information_loss.pdf&#39;, bbox_inches=&#39;tight&#39;)

        # Plot for relational information loss
        ril_plot = relational_information_loss.plot(xticks=k_values, marker=&#39;o&#39;, color=colors)
        ril_plot.legend(il_legend_names, loc=&#39;lower center&#39;, ncol=3, fancybox=True, bbox_to_anchor=(0.5, -0.3))
        ril_fig = ril_plot.get_figure()
        ril_fig.set_figheight(fig_height)
        ril_fig.set_figwidth(fig_width)
        ril_plot.set_xlabel(&#39;k&#39;)
        ril_plot.set_ylabel(&#39;$NCP_A$&#39;, rotation=90)
        ril_plot.set_ylim([y_min, y_max])
        ril_plot.set_yticks(y_ticks)
        ril_fig.tight_layout()
        ril_fig.savefig(result_directory / &#39;relational_information_loss.pgf&#39;)
        ril_fig.savefig(result_directory / &#39;relational_information_loss.pdf&#39;, bbox_inches=&#39;tight&#39;)

        # Plot for textual information loss
        xil_plot = textual_information_loss.plot(xticks=k_values, marker=&#39;o&#39;, color=colors)
        xil_plot.legend(il_legend_names, loc=&#39;lower center&#39;, ncol=3, fancybox=True, bbox_to_anchor=(0.5, -0.3))
        xil_fig = xil_plot.get_figure()
        xil_fig.set_figheight(fig_height)
        xil_fig.set_figwidth(fig_width)
        xil_plot.set_xlabel(&#39;k&#39;)
        xil_plot.set_ylabel(&#39;$NCP_X$&#39;, rotation=90)
        xil_plot.set_ylim([y_min, y_max])
        xil_plot.set_yticks(y_ticks)
        xil_fig.tight_layout()
        xil_fig.savefig(result_directory / &#39;textual_information_loss.pgf&#39;)
        xil_fig.savefig(result_directory / &#39;textual_information_loss.pdf&#39;, bbox_inches=&#39;tight&#39;)

        xil_zoomed = textual_information_loss.plot(xticks=k_values, marker=&#39;o&#39;, color=colors)
        xil_zoomed.legend(il_legend_names, loc=&#39;lower center&#39;, ncol=3, fancybox=True, bbox_to_anchor=(0.5, -0.3))
        xil_zoomed_fig = xil_zoomed.get_figure()
        xil_zoomed_fig.set_figheight(fig_height)
        xil_zoomed_fig.set_figwidth(fig_width)
        xil_zoomed.set_xlabel(&#39;k&#39;)
        xil_zoomed.set_ylabel(&#39;$NCP_X$&#39;, rotation=90)
        xil_zoomed_fig.tight_layout()
        xil_zoomed_fig.savefig(result_directory / &#39;textual_information_loss_zoomed.pgf&#39;)
        xil_zoomed_fig.savefig(result_directory / &#39;textual_information_loss_zoomed.pdf&#39;, bbox_inches=&#39;tight&#39;)

    # Combined plot
    combined_results = [&#34;blogs&#34;, &#34;hotels&#34;]
    pad = 5  # in points
    for ii, (ps_c_fig, ps_c_axes) in enumerate([(ps_c_blogs_fig, ps_c_blogs_axes), (ps_c_hotels_fig, ps_c_hotels_axes)]):
        handles_labels = [ax.get_legend_handles_labels() for ax in ps_c_fig.axes]
        handles, labels = [sum(lol, []) for lol in zip(*handles_labels)]
        ps_c_fig.legend(handles, [&#34;relational attribute&#34;, &#34;textual attribute&#34;], loc=&#39;lower center&#39;, ncol=2, fancybox=True, bbox_to_anchor=(0.53, -0.03))
        ps_c_fig.set_figheight(2 * fig_height)
        ps_c_fig.set_figwidth(2 * fig_width)

        cols = [&#34;all entities&#34;, &#34;only GPE&#34;]
        rows = [&#34;$k={}$&#34;.format(k) for k in k_values]

        for ax, col in zip(ps_c_axes[0], cols):
            ax.set_title(col)

        for ax, row in zip(ps_c_axes[:, 0], rows):
            ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),
                        xycoords=ax.yaxis.label, textcoords=&#39;offset points&#39;,
                        size=&#39;large&#39;, ha=&#39;right&#39;, va=&#39;center&#39;, rotation=90)

        for ax, row in zip(ps_c_axes[:, 0], rows):
            ax.set_ylabel(&#34;number of splits&#34;, rotation=90)

        ps_c_fig.subplots_adjust(left=0.15, top=0.95)
        ps_c_fig.tight_layout()
        results_path = Path(&#34;experiment_results/results&#34;)
        ps_c_fig.savefig(results_path / &#39;partition_splits_combined_{}.pgf&#39;.format(combined_results[ii]), bbox_inches=&#39;tight&#39;)
        ps_c_fig.savefig(results_path / &#39;partition_splits_combined_{}.pdf&#39;.format(combined_results[ii]), bbox_inches=&#39;tight&#39;)</code></pre>
</details>
</dd>
<dt id="anon.evaluate_experiment_results.merge_experiment_results"><code class="name flex">
<span>def <span class="ident">merge_experiment_results</span></span>(<span>path)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_experiment_results(path):
    raw_files = [os.path.basename(child) for child in path.iterdir()]

    relational_information_loss_files = [child for child in raw_files if child.startswith(&#34;relational_information_loss_&#34;) and any(f in child for f in information_loss_filter)]
    textual_information_loss_files = [child for child in raw_files if child.startswith(&#34;textual_information_loss_&#34;) and any(f in child for f in information_loss_filter)]
    total_information_loss_files = [child for child in raw_files if child.startswith(&#34;total_information_loss_&#34;) and any(f in child for f in information_loss_filter)]
    partition_sizes_files = [child for child in raw_files if child.startswith(&#34;partition_distribution_&#34;)]
    partition_split_files = [child for child in raw_files if child.startswith(&#34;partition_splits_&#34;)]

    merge_information_loss_results(path, relational_information_loss_files, &#34;relational_information_loss.csv&#34;)
    merge_information_loss_results(path, textual_information_loss_files, &#34;textual_information_loss.csv&#34;)
    merge_information_loss_results(path, total_information_loss_files, &#34;total_information_loss.csv&#34;)
    merge_partition_json(path, partition_sizes_files, &#34;partition_distribution.json&#34;)
    merge_partition_json(path, partition_split_files, &#34;partition_splits.json&#34;)</code></pre>
</details>
</dd>
<dt id="anon.evaluate_experiment_results.merge_information_loss_results"><code class="name flex">
<span>def <span class="ident">merge_information_loss_results</span></span>(<span>path, information_loss_files, destination)</span>
</code></dt>
<dd>
<div class="desc"><p>Merges partial information loss files to a single file</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_information_loss_results(path, information_loss_files, destination):
    &#34;&#34;&#34;Merges partial information loss files to a single file&#34;&#34;&#34;
    data_frames = []
    if len(information_loss_files) &gt; 0:
        for information_loss_file in information_loss_files:
            data_frames.append(pd.read_csv(path / information_loss_file, index_col=&#34;k&#34;))
        df_il = pd.concat(data_frames, axis=1)
        df_il = df_il.reindex(sorted(df_il.columns), axis=1)
        df_il.to_csv(path / destination)</code></pre>
</details>
</dd>
<dt id="anon.evaluate_experiment_results.merge_partition_json"><code class="name flex">
<span>def <span class="ident">merge_partition_json</span></span>(<span>path, partition_size_files, destination)</span>
</code></dt>
<dd>
<div class="desc"><p>Merges partial partition size files to a single file</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_partition_json(path, partition_size_files, destination):
    &#34;&#34;&#34;Merges partial partition size files to a single file&#34;&#34;&#34;
    merged_partition_sizes = {}
    if len(partition_size_files) &gt; 0:
        for partition_size_file in partition_size_files:
            with open(path / partition_size_file) as partition_size_json:
                loaded_partition_sizes = json.load(partition_size_json)
                for partitioning_strategy in loaded_partition_sizes:
                    merged_partition_sizes[partitioning_strategy] = loaded_partition_sizes[partitioning_strategy]
    merged_partition_sizes = {k: v for k, v in sorted(merged_partition_sizes.items())}

    with open(path / destination, &#39;w&#39;) as partition_size_file:
        json.dump(merged_partition_sizes, partition_size_file, ensure_ascii=False)</code></pre>
</details>
</dd>
<dt id="anon.evaluate_experiment_results.set_box_color"><code class="name flex">
<span>def <span class="ident">set_box_color</span></span>(<span>bp, color)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_box_color(bp, color):
    plt.setp(bp[&#39;boxes&#39;], color=color)
    plt.setp(bp[&#39;whiskers&#39;], color=color)
    plt.setp(bp[&#39;caps&#39;], color=color)
    plt.setp(bp[&#39;medians&#39;], color=&#39;#000000&#39;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="anon" href="index.html">anon</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="anon.evaluate_experiment_results.main" href="#anon.evaluate_experiment_results.main">main</a></code></li>
<li><code><a title="anon.evaluate_experiment_results.merge_experiment_results" href="#anon.evaluate_experiment_results.merge_experiment_results">merge_experiment_results</a></code></li>
<li><code><a title="anon.evaluate_experiment_results.merge_information_loss_results" href="#anon.evaluate_experiment_results.merge_information_loss_results">merge_information_loss_results</a></code></li>
<li><code><a title="anon.evaluate_experiment_results.merge_partition_json" href="#anon.evaluate_experiment_results.merge_partition_json">merge_partition_json</a></code></li>
<li><code><a title="anon.evaluate_experiment_results.set_box_color" href="#anon.evaluate_experiment_results.set_box_color">set_box_color</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>
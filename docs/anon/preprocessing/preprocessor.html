<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>anon.preprocessing.preprocessor API documentation</title>
<meta name="description" content="This module contains code to prepare an RX-dataset for anonymization" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>anon.preprocessing.preprocessor</code></h1>
</header>
<section id="section-intro">
<p>This module contains code to prepare an RX-dataset for anonymization</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;This module contains code to prepare an RX-dataset for anonymization&#34;&#34;&#34;
import logging

from datetime import datetime

from nlp.similarity_module import compare_datetime, compare_using_equality
from tqdm import tqdm

from preprocessing.text_cleaning import remove_html_tags, remove_non_printable_characters, remove_unnecessary_spaces

logger = logging.getLogger(__name__)


class Preprocessor:
    &#34;&#34;&#34;Stateful preprocessor which takes care of all prepraration to anonymize a dataset including detection of sensitive terms&#34;&#34;&#34;

    def __init__(self, ner, config, df):
        self.__ner = ner
        self.__config = config
        self.__df = df

        self.__relational_attributes = []
        self.__textual_attributes = []
        self.__non_redundant_entity_attributes = []
        self.__redundant_entity_attributes = []

        self.__prepare()

    def __prepare(self):
        self.__df.columns = map(str.lower, self.__df.columns)
        for attribute in self.__df.columns:
            anonymization_type = self.__config.attributes[attribute.lower()][&#34;anonymization_type&#34;]
            if (anonymization_type == &#34;text&#34;):
                self.__textual_attributes.append(attribute)
            else:
                self.__relational_attributes.append(attribute)

    def clean_textual_attributes(self):
        &#34;&#34;&#34;
        Removes unprintable characters, HTML characters and unnecessary spaces from texts
        &#34;&#34;&#34;
        for attribute in self.__textual_attributes:
            for index, text in self.__df[attribute].dropna().iteritems():
                text = remove_non_printable_characters(text)
                text = remove_html_tags(text)
                text = remove_unnecessary_spaces(text)
                self.__df.at[index, attribute] = text

    def analyze_textual_attributes(self):
        &#34;&#34;&#34;
        Analyzes textual attributes on sensitive terms
        &#34;&#34;&#34;
        for attribute in self.__textual_attributes:
            self.__analyze_textual_attribute(attribute)

    def __analyze_textual_attribute(self, textual_attribute):
        logger.info(&#34;Analyzing texts of attribute %s&#34;, textual_attribute)

        texts_to_analyze = {}
        for index, text in self.__df[textual_attribute].dropna().iteritems():
            record_id = self.__df[self.__config.get_key_attribute()][index]
            texts_to_analyze.setdefault(record_id, []).append((text, index))

        entities_per_record = self.__ner.recognize(textual_attribute, texts_to_analyze)
        logger.info(&#34;Converting results of analysis for further processing&#34;)
        for entity_type in self.__entities_to_consider():
            entities_found = []
            for index in tqdm(self.__df[textual_attribute].index, desc=entity_type):
                if index in entities_per_record:
                    entities = entities_per_record[index]
                    if entity_type in entities:
                        entities_found.append(list(entities[entity_type]))
                    else:
                        entities_found.append(None)
                else:
                    entities_found.append(None)
            non_redundant_attribute_name = self.__build_non_redundant_attribute_name(textual_attribute, entity_type)
            self.__df[non_redundant_attribute_name] = entities_found
            self.__non_redundant_entity_attributes.append(non_redundant_attribute_name)

    def get_non_redundant_entity_attributes(self):
        &#34;&#34;&#34;
        Returns non-redundant entity columns.
        Returns
        -------
        list
            List containing non-redundant entity columns.
        &#34;&#34;&#34;
        return self.__non_redundant_entity_attributes

    def get_redundant_entity_attributes(self):
        &#34;&#34;&#34;
        Returns redundant entity columns.
        Returns
        -------
        list
            List containing redundant entity columns.
        &#34;&#34;&#34;
        return self.__redundant_entity_attributes

    def __entities_to_consider(self):
        return set(self.__config.get_entities_to_consider()).intersection(set(self.__ner.get_recognized_entities()))

    def __build_non_redundant_attribute_name(self, attribute, entity_type):
        return &#34;{}_{}&#34;.format(attribute, entity_type)

    def __build_redundant_attribute_name(self, attribute, entity_type):
        return &#34;{}_{}_&#34;.format(attribute, entity_type)

    def find_redundant_information(self):
        &#34;&#34;&#34;
        Resolves redundant information.
        &#34;&#34;&#34;
        for attribute in self.__textual_attributes:
            self.__find_redundant_information(attribute)

    def compress(self):
        &#34;&#34;&#34;
        Creates a person centric view of the dataset by grouping and aggregating based on the first direct identifier.
        &#34;&#34;&#34;
        aggregation_functions = {}
        for attribute in self.__df.columns:
            aggregation_functions[attribute] = self.__aggregate
        grouped_df = self.__df.groupby(by=[self.__config.get_key_attribute()], as_index=False)
        self.__df = grouped_df.agg(aggregation_functions)
        self.__df = self.__df.astype(self.__config.get_data_types())

    def get_sensitive_terms(self):
        &#34;&#34;&#34;
        Builds a dictionary containing terms and their appearances, categorized by entity type
        Returns
        -------
        list
            Dictionary containing terms and their appearances, categorized by entity type.
        &#34;&#34;&#34;
        sensitive_terms_dict = {}
        for attribute in self.__non_redundant_entity_attributes:
            for record_id, sensitive_terms in self.__df[attribute].dropna().iteritems():
                for sensitive_term in sensitive_terms:
                    cleaned_sensitive_term = &#34; &#34;.join([t.lemma_.lower() for t in sensitive_term if not t.is_stop])
                    if len(cleaned_sensitive_term) &gt; 0:
                        sensitive_terms_dict.setdefault(attribute, {}).setdefault(cleaned_sensitive_term, set()).add(record_id)

        # Sort sensitive terms dict alphabetically to have a deterministic order
        sensitive_terms_dict = {el[0]: el[1] for el in sorted(sensitive_terms_dict.items(), key=lambda x: x)}

        # Sort sensitive terms dict ascending by number terms per entity type
        sensitive_terms_dict = {el[0]: el[1] for el in sorted(sensitive_terms_dict.items(), key=lambda x: len(x[1]))}

        for attribute, sensitive_terms in sensitive_terms_dict.items():
            word = &#34;terms&#34;
            if len(sensitive_terms) == 1:
                word = &#34;term&#34;
            logger.info(&#34;Found %d distinct sensitive %s within attribute %s&#34;, len(sensitive_terms), word, attribute)
        return sensitive_terms_dict

    def get_df(self):
        &#34;&#34;&#34;
        Returns the current status of the data frame.
        Returns
        -------
        DataFrame
            DataFrame with current state.
        &#34;&#34;&#34;
        return self.__df

    def get_textual_attribute_mapping(self):
        &#34;&#34;&#34;
        Returns a dictionary with the original textual attribute as key and the new temporary non redundant entity attributes as values.
        Returns
        -------
        dict
            Dictionary with textual attributes and non-redundant entity attributes as values.
        &#34;&#34;&#34;
        textual_attributes = self.__config.get_textual_attributes()
        textual_attributes_mapping = {}
        for textual_attribute in textual_attributes:
            textual_attributes_mapping[textual_attribute] = [attribute for attribute in self.__non_redundant_entity_attributes if textual_attribute in attribute]
        return textual_attributes_mapping

    def __find_redundant_information(self, textual_attribute):
        logger.info(&#34;Looking for redundant information for attribute %s&#34;, textual_attribute)
        mapping = self.__config.get_attribute_entities_mapping()
        for entity_type in mapping:
            redundant_values = []
            redundant_found = False
            non_redundant_attribute_name = self.__build_non_redundant_attribute_name(textual_attribute, entity_type)
            if non_redundant_attribute_name not in self.__df.columns:
                logger.warning(&#34;Skipping entities of type %s for attribute %s since no entities exist.&#34;, entity_type, textual_attribute)
                continue

            for record_id in tqdm(self.__df.index, desc=entity_type):
                entities_of_record = self.__df.at[record_id, non_redundant_attribute_name]
                if entities_of_record:
                    redundant_information = self.__get_redundant_information(record_id, entities_of_record, mapping[entity_type])
                    if len(redundant_information) &gt; 0:
                        redundant_found = True
                        redundant_values.append(list(redundant_information))
                        redundant_entities = set([e[0] for e in redundant_information])
                        non_redundant_values = list(set(self.__df.at[record_id, non_redundant_attribute_name]).difference(redundant_entities))  # Removing redundant terms from non redundant attribute
                        if len(non_redundant_values) == 0:
                            self.__df.at[record_id, non_redundant_attribute_name] = None  # Set to None if all sensitive terms are redundant
                        else:
                            self.__df.at[record_id, non_redundant_attribute_name] = non_redundant_values
                    else:
                        redundant_values.append(None)
                else:
                    redundant_values.append(None)

            if redundant_found:  # Create this series and extend dataframe
                redundant_attribute_name = self.__build_redundant_attribute_name(textual_attribute, entity_type)
                self.__redundant_entity_attributes.append(redundant_attribute_name)
                self.__df[redundant_attribute_name] = redundant_values

        self.__drop_empty_series()

        for redundant_entity_attribute in self.__redundant_entity_attributes:
            series = self.__df[redundant_entity_attribute].dropna()
            total = len(series.tolist())
            logger.info(&#34;Found redundant sensitive terms in %d records for attribute %s&#34;, total, redundant_entity_attribute)

    def __aggregate(self, series):
        &#34;&#34;&#34;Used to aggregate data of a dataset, without losing any information.&#34;&#34;&#34;
        if series.name in self.__non_redundant_entity_attributes or series.name in self.__redundant_entity_attributes:  # Textual entities
            merged_sensitive_terms = list()
            for sensitive_terms in series.dropna():
                merged_sensitive_terms = merged_sensitive_terms + sensitive_terms
            return merged_sensitive_terms if len(merged_sensitive_terms) &gt; 0 else None  # Return merged result, or None
        else:
            if series.nunique() &gt; 1:  # Since there are more values, pack them into a list / frozenset
                if series.name in self.__textual_attributes or series.name in self.__config.get_insensitive_attributes():
                    return list(series.array)
                else:
                    return frozenset(series.array)
            else:
                return series.unique()[0]  # Else return just this single value

    def __get_redundant_information(self, record_id, textual_values, relational_attributes):
        redundant_information = set()
        for attribute, relational_value in self.__df[relational_attributes].loc[record_id].iteritems():
            for textual_value in textual_values:
                if isinstance(relational_value, datetime):
                    result = compare_datetime(relational_value, textual_value)
                    right_matching_token = textual_value
                else:
                    nlp = self.__ner.get_nlp()
                    relational_token = nlp(str(relational_value))
                    result, _, right_matching_token = compare_using_equality(relational_token, textual_value)
                if result:
                    redundant_information.add((textual_value, right_matching_token, attribute))
        return redundant_information

    def __drop_empty_series(self):
        attributes_pre_drop = set(self.__df.columns)
        self.__df.dropna(axis=1, how=&#39;all&#39;, inplace=True)
        attributes_post_drop = set(self.__df.columns)
        attributes_dropped = attributes_pre_drop.difference(attributes_post_drop)
        if len(attributes_dropped) &gt; 0:
            logger.warning(&#34;Dropped the attributes %s due to emptyness&#34;, &#34;, &#34;.join(attributes_dropped))
        self.__non_redundant_entity_attributes = set(self.__non_redundant_entity_attributes).intersection(attributes_post_drop)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="anon.preprocessing.preprocessor.Preprocessor"><code class="flex name class">
<span>class <span class="ident">Preprocessor</span></span>
<span>(</span><span>ner, config, df)</span>
</code></dt>
<dd>
<div class="desc"><p>Stateful preprocessor which takes care of all prepraration to anonymize a dataset including detection of sensitive terms</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Preprocessor:
    &#34;&#34;&#34;Stateful preprocessor which takes care of all prepraration to anonymize a dataset including detection of sensitive terms&#34;&#34;&#34;

    def __init__(self, ner, config, df):
        self.__ner = ner
        self.__config = config
        self.__df = df

        self.__relational_attributes = []
        self.__textual_attributes = []
        self.__non_redundant_entity_attributes = []
        self.__redundant_entity_attributes = []

        self.__prepare()

    def __prepare(self):
        self.__df.columns = map(str.lower, self.__df.columns)
        for attribute in self.__df.columns:
            anonymization_type = self.__config.attributes[attribute.lower()][&#34;anonymization_type&#34;]
            if (anonymization_type == &#34;text&#34;):
                self.__textual_attributes.append(attribute)
            else:
                self.__relational_attributes.append(attribute)

    def clean_textual_attributes(self):
        &#34;&#34;&#34;
        Removes unprintable characters, HTML characters and unnecessary spaces from texts
        &#34;&#34;&#34;
        for attribute in self.__textual_attributes:
            for index, text in self.__df[attribute].dropna().iteritems():
                text = remove_non_printable_characters(text)
                text = remove_html_tags(text)
                text = remove_unnecessary_spaces(text)
                self.__df.at[index, attribute] = text

    def analyze_textual_attributes(self):
        &#34;&#34;&#34;
        Analyzes textual attributes on sensitive terms
        &#34;&#34;&#34;
        for attribute in self.__textual_attributes:
            self.__analyze_textual_attribute(attribute)

    def __analyze_textual_attribute(self, textual_attribute):
        logger.info(&#34;Analyzing texts of attribute %s&#34;, textual_attribute)

        texts_to_analyze = {}
        for index, text in self.__df[textual_attribute].dropna().iteritems():
            record_id = self.__df[self.__config.get_key_attribute()][index]
            texts_to_analyze.setdefault(record_id, []).append((text, index))

        entities_per_record = self.__ner.recognize(textual_attribute, texts_to_analyze)
        logger.info(&#34;Converting results of analysis for further processing&#34;)
        for entity_type in self.__entities_to_consider():
            entities_found = []
            for index in tqdm(self.__df[textual_attribute].index, desc=entity_type):
                if index in entities_per_record:
                    entities = entities_per_record[index]
                    if entity_type in entities:
                        entities_found.append(list(entities[entity_type]))
                    else:
                        entities_found.append(None)
                else:
                    entities_found.append(None)
            non_redundant_attribute_name = self.__build_non_redundant_attribute_name(textual_attribute, entity_type)
            self.__df[non_redundant_attribute_name] = entities_found
            self.__non_redundant_entity_attributes.append(non_redundant_attribute_name)

    def get_non_redundant_entity_attributes(self):
        &#34;&#34;&#34;
        Returns non-redundant entity columns.
        Returns
        -------
        list
            List containing non-redundant entity columns.
        &#34;&#34;&#34;
        return self.__non_redundant_entity_attributes

    def get_redundant_entity_attributes(self):
        &#34;&#34;&#34;
        Returns redundant entity columns.
        Returns
        -------
        list
            List containing redundant entity columns.
        &#34;&#34;&#34;
        return self.__redundant_entity_attributes

    def __entities_to_consider(self):
        return set(self.__config.get_entities_to_consider()).intersection(set(self.__ner.get_recognized_entities()))

    def __build_non_redundant_attribute_name(self, attribute, entity_type):
        return &#34;{}_{}&#34;.format(attribute, entity_type)

    def __build_redundant_attribute_name(self, attribute, entity_type):
        return &#34;{}_{}_&#34;.format(attribute, entity_type)

    def find_redundant_information(self):
        &#34;&#34;&#34;
        Resolves redundant information.
        &#34;&#34;&#34;
        for attribute in self.__textual_attributes:
            self.__find_redundant_information(attribute)

    def compress(self):
        &#34;&#34;&#34;
        Creates a person centric view of the dataset by grouping and aggregating based on the first direct identifier.
        &#34;&#34;&#34;
        aggregation_functions = {}
        for attribute in self.__df.columns:
            aggregation_functions[attribute] = self.__aggregate
        grouped_df = self.__df.groupby(by=[self.__config.get_key_attribute()], as_index=False)
        self.__df = grouped_df.agg(aggregation_functions)
        self.__df = self.__df.astype(self.__config.get_data_types())

    def get_sensitive_terms(self):
        &#34;&#34;&#34;
        Builds a dictionary containing terms and their appearances, categorized by entity type
        Returns
        -------
        list
            Dictionary containing terms and their appearances, categorized by entity type.
        &#34;&#34;&#34;
        sensitive_terms_dict = {}
        for attribute in self.__non_redundant_entity_attributes:
            for record_id, sensitive_terms in self.__df[attribute].dropna().iteritems():
                for sensitive_term in sensitive_terms:
                    cleaned_sensitive_term = &#34; &#34;.join([t.lemma_.lower() for t in sensitive_term if not t.is_stop])
                    if len(cleaned_sensitive_term) &gt; 0:
                        sensitive_terms_dict.setdefault(attribute, {}).setdefault(cleaned_sensitive_term, set()).add(record_id)

        # Sort sensitive terms dict alphabetically to have a deterministic order
        sensitive_terms_dict = {el[0]: el[1] for el in sorted(sensitive_terms_dict.items(), key=lambda x: x)}

        # Sort sensitive terms dict ascending by number terms per entity type
        sensitive_terms_dict = {el[0]: el[1] for el in sorted(sensitive_terms_dict.items(), key=lambda x: len(x[1]))}

        for attribute, sensitive_terms in sensitive_terms_dict.items():
            word = &#34;terms&#34;
            if len(sensitive_terms) == 1:
                word = &#34;term&#34;
            logger.info(&#34;Found %d distinct sensitive %s within attribute %s&#34;, len(sensitive_terms), word, attribute)
        return sensitive_terms_dict

    def get_df(self):
        &#34;&#34;&#34;
        Returns the current status of the data frame.
        Returns
        -------
        DataFrame
            DataFrame with current state.
        &#34;&#34;&#34;
        return self.__df

    def get_textual_attribute_mapping(self):
        &#34;&#34;&#34;
        Returns a dictionary with the original textual attribute as key and the new temporary non redundant entity attributes as values.
        Returns
        -------
        dict
            Dictionary with textual attributes and non-redundant entity attributes as values.
        &#34;&#34;&#34;
        textual_attributes = self.__config.get_textual_attributes()
        textual_attributes_mapping = {}
        for textual_attribute in textual_attributes:
            textual_attributes_mapping[textual_attribute] = [attribute for attribute in self.__non_redundant_entity_attributes if textual_attribute in attribute]
        return textual_attributes_mapping

    def __find_redundant_information(self, textual_attribute):
        logger.info(&#34;Looking for redundant information for attribute %s&#34;, textual_attribute)
        mapping = self.__config.get_attribute_entities_mapping()
        for entity_type in mapping:
            redundant_values = []
            redundant_found = False
            non_redundant_attribute_name = self.__build_non_redundant_attribute_name(textual_attribute, entity_type)
            if non_redundant_attribute_name not in self.__df.columns:
                logger.warning(&#34;Skipping entities of type %s for attribute %s since no entities exist.&#34;, entity_type, textual_attribute)
                continue

            for record_id in tqdm(self.__df.index, desc=entity_type):
                entities_of_record = self.__df.at[record_id, non_redundant_attribute_name]
                if entities_of_record:
                    redundant_information = self.__get_redundant_information(record_id, entities_of_record, mapping[entity_type])
                    if len(redundant_information) &gt; 0:
                        redundant_found = True
                        redundant_values.append(list(redundant_information))
                        redundant_entities = set([e[0] for e in redundant_information])
                        non_redundant_values = list(set(self.__df.at[record_id, non_redundant_attribute_name]).difference(redundant_entities))  # Removing redundant terms from non redundant attribute
                        if len(non_redundant_values) == 0:
                            self.__df.at[record_id, non_redundant_attribute_name] = None  # Set to None if all sensitive terms are redundant
                        else:
                            self.__df.at[record_id, non_redundant_attribute_name] = non_redundant_values
                    else:
                        redundant_values.append(None)
                else:
                    redundant_values.append(None)

            if redundant_found:  # Create this series and extend dataframe
                redundant_attribute_name = self.__build_redundant_attribute_name(textual_attribute, entity_type)
                self.__redundant_entity_attributes.append(redundant_attribute_name)
                self.__df[redundant_attribute_name] = redundant_values

        self.__drop_empty_series()

        for redundant_entity_attribute in self.__redundant_entity_attributes:
            series = self.__df[redundant_entity_attribute].dropna()
            total = len(series.tolist())
            logger.info(&#34;Found redundant sensitive terms in %d records for attribute %s&#34;, total, redundant_entity_attribute)

    def __aggregate(self, series):
        &#34;&#34;&#34;Used to aggregate data of a dataset, without losing any information.&#34;&#34;&#34;
        if series.name in self.__non_redundant_entity_attributes or series.name in self.__redundant_entity_attributes:  # Textual entities
            merged_sensitive_terms = list()
            for sensitive_terms in series.dropna():
                merged_sensitive_terms = merged_sensitive_terms + sensitive_terms
            return merged_sensitive_terms if len(merged_sensitive_terms) &gt; 0 else None  # Return merged result, or None
        else:
            if series.nunique() &gt; 1:  # Since there are more values, pack them into a list / frozenset
                if series.name in self.__textual_attributes or series.name in self.__config.get_insensitive_attributes():
                    return list(series.array)
                else:
                    return frozenset(series.array)
            else:
                return series.unique()[0]  # Else return just this single value

    def __get_redundant_information(self, record_id, textual_values, relational_attributes):
        redundant_information = set()
        for attribute, relational_value in self.__df[relational_attributes].loc[record_id].iteritems():
            for textual_value in textual_values:
                if isinstance(relational_value, datetime):
                    result = compare_datetime(relational_value, textual_value)
                    right_matching_token = textual_value
                else:
                    nlp = self.__ner.get_nlp()
                    relational_token = nlp(str(relational_value))
                    result, _, right_matching_token = compare_using_equality(relational_token, textual_value)
                if result:
                    redundant_information.add((textual_value, right_matching_token, attribute))
        return redundant_information

    def __drop_empty_series(self):
        attributes_pre_drop = set(self.__df.columns)
        self.__df.dropna(axis=1, how=&#39;all&#39;, inplace=True)
        attributes_post_drop = set(self.__df.columns)
        attributes_dropped = attributes_pre_drop.difference(attributes_post_drop)
        if len(attributes_dropped) &gt; 0:
            logger.warning(&#34;Dropped the attributes %s due to emptyness&#34;, &#34;, &#34;.join(attributes_dropped))
        self.__non_redundant_entity_attributes = set(self.__non_redundant_entity_attributes).intersection(attributes_post_drop)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="anon.preprocessing.preprocessor.Preprocessor.analyze_textual_attributes"><code class="name flex">
<span>def <span class="ident">analyze_textual_attributes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Analyzes textual attributes on sensitive terms</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def analyze_textual_attributes(self):
    &#34;&#34;&#34;
    Analyzes textual attributes on sensitive terms
    &#34;&#34;&#34;
    for attribute in self.__textual_attributes:
        self.__analyze_textual_attribute(attribute)</code></pre>
</details>
</dd>
<dt id="anon.preprocessing.preprocessor.Preprocessor.clean_textual_attributes"><code class="name flex">
<span>def <span class="ident">clean_textual_attributes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Removes unprintable characters, HTML characters and unnecessary spaces from texts</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_textual_attributes(self):
    &#34;&#34;&#34;
    Removes unprintable characters, HTML characters and unnecessary spaces from texts
    &#34;&#34;&#34;
    for attribute in self.__textual_attributes:
        for index, text in self.__df[attribute].dropna().iteritems():
            text = remove_non_printable_characters(text)
            text = remove_html_tags(text)
            text = remove_unnecessary_spaces(text)
            self.__df.at[index, attribute] = text</code></pre>
</details>
</dd>
<dt id="anon.preprocessing.preprocessor.Preprocessor.compress"><code class="name flex">
<span>def <span class="ident">compress</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a person centric view of the dataset by grouping and aggregating based on the first direct identifier.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compress(self):
    &#34;&#34;&#34;
    Creates a person centric view of the dataset by grouping and aggregating based on the first direct identifier.
    &#34;&#34;&#34;
    aggregation_functions = {}
    for attribute in self.__df.columns:
        aggregation_functions[attribute] = self.__aggregate
    grouped_df = self.__df.groupby(by=[self.__config.get_key_attribute()], as_index=False)
    self.__df = grouped_df.agg(aggregation_functions)
    self.__df = self.__df.astype(self.__config.get_data_types())</code></pre>
</details>
</dd>
<dt id="anon.preprocessing.preprocessor.Preprocessor.find_redundant_information"><code class="name flex">
<span>def <span class="ident">find_redundant_information</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Resolves redundant information.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_redundant_information(self):
    &#34;&#34;&#34;
    Resolves redundant information.
    &#34;&#34;&#34;
    for attribute in self.__textual_attributes:
        self.__find_redundant_information(attribute)</code></pre>
</details>
</dd>
<dt id="anon.preprocessing.preprocessor.Preprocessor.get_df"><code class="name flex">
<span>def <span class="ident">get_df</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the current status of the data frame.
Returns</p>
<hr>
<dl>
<dt><code>DataFrame</code></dt>
<dd>DataFrame with current state.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_df(self):
    &#34;&#34;&#34;
    Returns the current status of the data frame.
    Returns
    -------
    DataFrame
        DataFrame with current state.
    &#34;&#34;&#34;
    return self.__df</code></pre>
</details>
</dd>
<dt id="anon.preprocessing.preprocessor.Preprocessor.get_non_redundant_entity_attributes"><code class="name flex">
<span>def <span class="ident">get_non_redundant_entity_attributes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns non-redundant entity columns.
Returns</p>
<hr>
<dl>
<dt><code>list</code></dt>
<dd>List containing non-redundant entity columns.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_non_redundant_entity_attributes(self):
    &#34;&#34;&#34;
    Returns non-redundant entity columns.
    Returns
    -------
    list
        List containing non-redundant entity columns.
    &#34;&#34;&#34;
    return self.__non_redundant_entity_attributes</code></pre>
</details>
</dd>
<dt id="anon.preprocessing.preprocessor.Preprocessor.get_redundant_entity_attributes"><code class="name flex">
<span>def <span class="ident">get_redundant_entity_attributes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns redundant entity columns.
Returns</p>
<hr>
<dl>
<dt><code>list</code></dt>
<dd>List containing redundant entity columns.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_redundant_entity_attributes(self):
    &#34;&#34;&#34;
    Returns redundant entity columns.
    Returns
    -------
    list
        List containing redundant entity columns.
    &#34;&#34;&#34;
    return self.__redundant_entity_attributes</code></pre>
</details>
</dd>
<dt id="anon.preprocessing.preprocessor.Preprocessor.get_sensitive_terms"><code class="name flex">
<span>def <span class="ident">get_sensitive_terms</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Builds a dictionary containing terms and their appearances, categorized by entity type
Returns</p>
<hr>
<dl>
<dt><code>list</code></dt>
<dd>Dictionary containing terms and their appearances, categorized by entity type.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_sensitive_terms(self):
    &#34;&#34;&#34;
    Builds a dictionary containing terms and their appearances, categorized by entity type
    Returns
    -------
    list
        Dictionary containing terms and their appearances, categorized by entity type.
    &#34;&#34;&#34;
    sensitive_terms_dict = {}
    for attribute in self.__non_redundant_entity_attributes:
        for record_id, sensitive_terms in self.__df[attribute].dropna().iteritems():
            for sensitive_term in sensitive_terms:
                cleaned_sensitive_term = &#34; &#34;.join([t.lemma_.lower() for t in sensitive_term if not t.is_stop])
                if len(cleaned_sensitive_term) &gt; 0:
                    sensitive_terms_dict.setdefault(attribute, {}).setdefault(cleaned_sensitive_term, set()).add(record_id)

    # Sort sensitive terms dict alphabetically to have a deterministic order
    sensitive_terms_dict = {el[0]: el[1] for el in sorted(sensitive_terms_dict.items(), key=lambda x: x)}

    # Sort sensitive terms dict ascending by number terms per entity type
    sensitive_terms_dict = {el[0]: el[1] for el in sorted(sensitive_terms_dict.items(), key=lambda x: len(x[1]))}

    for attribute, sensitive_terms in sensitive_terms_dict.items():
        word = &#34;terms&#34;
        if len(sensitive_terms) == 1:
            word = &#34;term&#34;
        logger.info(&#34;Found %d distinct sensitive %s within attribute %s&#34;, len(sensitive_terms), word, attribute)
    return sensitive_terms_dict</code></pre>
</details>
</dd>
<dt id="anon.preprocessing.preprocessor.Preprocessor.get_textual_attribute_mapping"><code class="name flex">
<span>def <span class="ident">get_textual_attribute_mapping</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a dictionary with the original textual attribute as key and the new temporary non redundant entity attributes as values.
Returns</p>
<hr>
<dl>
<dt><code>dict</code></dt>
<dd>Dictionary with textual attributes and non-redundant entity attributes as values.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_textual_attribute_mapping(self):
    &#34;&#34;&#34;
    Returns a dictionary with the original textual attribute as key and the new temporary non redundant entity attributes as values.
    Returns
    -------
    dict
        Dictionary with textual attributes and non-redundant entity attributes as values.
    &#34;&#34;&#34;
    textual_attributes = self.__config.get_textual_attributes()
    textual_attributes_mapping = {}
    for textual_attribute in textual_attributes:
        textual_attributes_mapping[textual_attribute] = [attribute for attribute in self.__non_redundant_entity_attributes if textual_attribute in attribute]
    return textual_attributes_mapping</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="anon.preprocessing" href="index.html">anon.preprocessing</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="anon.preprocessing.preprocessor.Preprocessor" href="#anon.preprocessing.preprocessor.Preprocessor">Preprocessor</a></code></h4>
<ul class="">
<li><code><a title="anon.preprocessing.preprocessor.Preprocessor.analyze_textual_attributes" href="#anon.preprocessing.preprocessor.Preprocessor.analyze_textual_attributes">analyze_textual_attributes</a></code></li>
<li><code><a title="anon.preprocessing.preprocessor.Preprocessor.clean_textual_attributes" href="#anon.preprocessing.preprocessor.Preprocessor.clean_textual_attributes">clean_textual_attributes</a></code></li>
<li><code><a title="anon.preprocessing.preprocessor.Preprocessor.compress" href="#anon.preprocessing.preprocessor.Preprocessor.compress">compress</a></code></li>
<li><code><a title="anon.preprocessing.preprocessor.Preprocessor.find_redundant_information" href="#anon.preprocessing.preprocessor.Preprocessor.find_redundant_information">find_redundant_information</a></code></li>
<li><code><a title="anon.preprocessing.preprocessor.Preprocessor.get_df" href="#anon.preprocessing.preprocessor.Preprocessor.get_df">get_df</a></code></li>
<li><code><a title="anon.preprocessing.preprocessor.Preprocessor.get_non_redundant_entity_attributes" href="#anon.preprocessing.preprocessor.Preprocessor.get_non_redundant_entity_attributes">get_non_redundant_entity_attributes</a></code></li>
<li><code><a title="anon.preprocessing.preprocessor.Preprocessor.get_redundant_entity_attributes" href="#anon.preprocessing.preprocessor.Preprocessor.get_redundant_entity_attributes">get_redundant_entity_attributes</a></code></li>
<li><code><a title="anon.preprocessing.preprocessor.Preprocessor.get_sensitive_terms" href="#anon.preprocessing.preprocessor.Preprocessor.get_sensitive_terms">get_sensitive_terms</a></code></li>
<li><code><a title="anon.preprocessing.preprocessor.Preprocessor.get_textual_attribute_mapping" href="#anon.preprocessing.preprocessor.Preprocessor.get_textual_attribute_mapping">get_textual_attribute_mapping</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>